{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COMP41680 Assignment 2: Text Classification\n",
    "Student Name- Vidushi Jain <br/>\n",
    "Student Number- 18200009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import csv\n",
    "import pandas as pd \n",
    "import sys,socket\n",
    "import requests\n",
    "import math\n",
    "import json\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 \n",
    "\n",
    "Select two review categories of your choice. Scrape all reviews for each category and store them as two separate datasets. For each review, you should store the review text and a class label (i.e. whether the review is “positive” or “negative”)\n",
    "\n",
    "For this task, I have chosen <b>'Bars' and 'Hotels and travel'</b> category. From the main page, I am extracting the URL of these two categories. Then I am looping through each URL. For each URL, I am iterating over each business in that particular category. Then for each business, I am looping through reviews and fetching it's text and number of stars. At the end, I am storing the data in two dataframes separately for both categories.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_page_url='http://mlg.ucd.ie/modules/yalp/'\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "response = requests.get(main_page_url,headers=headers)\n",
    "content = response.content\n",
    "soup = BeautifulSoup(content,\"html.parser\")  \n",
    "headings = soup.find_all('a')\n",
    "category_url_list=[]\n",
    "for link in headings:\n",
    "    if(link.text == 'Category: Bars' or link.text == 'Category: Hotels and travel'):\n",
    "        category_url_list.append('http://mlg.ucd.ie/modules/yalp/%s'%(link['href']))\n",
    "        \n",
    "category_count=0;\n",
    "bars_reviews_value=[]\n",
    "hotels_travel_reviews_value=[]\n",
    "    \n",
    "for url in category_url_list:\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "    response = requests.get(url,headers=headers)\n",
    "    content = response.content\n",
    "    soup = BeautifulSoup(content,\"html.parser\")\n",
    "    headings = soup.find_all('h6')\n",
    "    for heading in headings:\n",
    "        url=heading.find('a')['href']\n",
    "        #business_name=heading.find('a').contents[0]\n",
    "        request_url='http://mlg.ucd.ie/modules/yalp/%s'%(url)\n",
    "        response = requests.get(request_url,headers=headers)\n",
    "        content = response.content\n",
    "        soup = BeautifulSoup(content,\"html.parser\")    \n",
    "        reviews=soup.findAll('div', attrs={'class':'review'})\n",
    "        for review in reviews:\n",
    "            star_p=review.find('p', attrs={'class':'stars'})\n",
    "            star_value=star_p.find('img')['alt']\n",
    "            text=review.find('p', attrs={'class':'text'}).contents[0]\n",
    "            if category_count == 0:\n",
    "                bars_reviews_value.append([text,star_value])\n",
    "            else:\n",
    "                hotels_travel_reviews_value.append([text,star_value]) \n",
    "                \n",
    "    category_count=category_count+1     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe from bars_reviews_value list which was created during the Web Scrapping and storing the data in a csv file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It would help if the front girl don't just sit us down and not ask us for drinks or put us with a waitress. Instead, let us just sit here for almost an hour unattended! If it's time for you to clock out then it's not our problem. But if you're gonna seat us be more professional about it at least then leave!</td>\n",
       "      <td>3-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One star because that's the least amount you can leave. I understand they have dollar margaritas but they should have enough people on staff to make all the food and get people seated and fed quickly. We came in restaurant seemed slow. Hostess said 10 minute wait to let the kitchen catch up. Well by the time we where seated the lobby was packed. As soon as we sat down we each ordered a water and a margarita we were a party of two. we place our order for food. That's where things went south. We sat for 45 minutes. The table that sat after us, ate and left before our appetizer ever came. I left a $5 on the table to cover margaritas. Never going back again.</td>\n",
       "      <td>1-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bad time today. Dirty windows, table sticky, handy payment/menu gadget yucky. Used my fork to enter info. Food was burned and dry. Only dark chocolate desserts. Adios.</td>\n",
       "      <td>2-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My second visit in the last year. Both experiences were similar: awful. Tonight, we arrived after my daughter's dance recital, so around 10pm. Not too crowded, thought it would be a quick place to grab some appetizers. NOT! Our party of 6 ordered 4 appetizers (3 of which were sample size), 2 house salads, and a kids meal. 30 minutes later, one appetizer came out, said the remainder of the food would be out in about 3 minutes. 10 minutes later, a different server brought the salads out (40 minutes after were seated, just for salads!) but we had no silverware. Another 5 minutes later, 2 more appetizers and the kids meal came out and we asked for silverware. Next time the server rolled around, we again asked for silverware, and were told \"I told her to get you some,\" referring to the hostess. He called across the restaurant to the hostess, who said she didn't have any silverware. He grumbled and went to find some. Several minutes later, our last appetizer, and silverware finally arrived. So almost a full hour before we had our entire meal and utensils to eat it with. We asked about the 50% off appetizer sign on the table and the dude actually said \"you got here after 9, and that's for after 10 on the weekends.\" He did finally honor the 50% off the regular appetizer when we basically had to tell him to look at the time on our ticket. . Not completely the server's fault, but the whole experience was horrible. After two very sub-par visits, my family will NEVER go back to this location.</td>\n",
       "      <td>1-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely awful! Took forever to get food, food then came out cold, we asked the manager to fix tv 3 times and it never got fix! The place was dead and it was still slower than molasses.</td>\n",
       "      <td>1-star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Review Text  \\\n",
       "0  It would help if the front girl don't just sit us down and not ask us for drinks or put us with a waitress. Instead, let us just sit here for almost an hour unattended! If it's time for you to clock out then it's not our problem. But if you're gonna seat us be more professional about it at least then leave!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                \n",
       "1  One star because that's the least amount you can leave. I understand they have dollar margaritas but they should have enough people on staff to make all the food and get people seated and fed quickly. We came in restaurant seemed slow. Hostess said 10 minute wait to let the kitchen catch up. Well by the time we where seated the lobby was packed. As soon as we sat down we each ordered a water and a margarita we were a party of two. we place our order for food. That's where things went south. We sat for 45 minutes. The table that sat after us, ate and left before our appetizer ever came. I left a $5 on the table to cover margaritas. Never going back again.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "2  Bad time today. Dirty windows, table sticky, handy payment/menu gadget yucky. Used my fork to enter info. Food was burned and dry. Only dark chocolate desserts. Adios.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "3  My second visit in the last year. Both experiences were similar: awful. Tonight, we arrived after my daughter's dance recital, so around 10pm. Not too crowded, thought it would be a quick place to grab some appetizers. NOT! Our party of 6 ordered 4 appetizers (3 of which were sample size), 2 house salads, and a kids meal. 30 minutes later, one appetizer came out, said the remainder of the food would be out in about 3 minutes. 10 minutes later, a different server brought the salads out (40 minutes after were seated, just for salads!) but we had no silverware. Another 5 minutes later, 2 more appetizers and the kids meal came out and we asked for silverware. Next time the server rolled around, we again asked for silverware, and were told \"I told her to get you some,\" referring to the hostess. He called across the restaurant to the hostess, who said she didn't have any silverware. He grumbled and went to find some. Several minutes later, our last appetizer, and silverware finally arrived. So almost a full hour before we had our entire meal and utensils to eat it with. We asked about the 50% off appetizer sign on the table and the dude actually said \"you got here after 9, and that's for after 10 on the weekends.\" He did finally honor the 50% off the regular appetizer when we basically had to tell him to look at the time on our ticket. . Not completely the server's fault, but the whole experience was horrible. After two very sub-par visits, my family will NEVER go back to this location.   \n",
       "4  Absolutely awful! Took forever to get food, food then came out cold, we asked the manager to fix tv 3 times and it never got fix! The place was dead and it was still slower than molasses.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         \n",
       "\n",
       "     Star  \n",
       "0  3-star  \n",
       "1  1-star  \n",
       "2  2-star  \n",
       "3  1-star  \n",
       "4  1-star  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars_dataset = pd.DataFrame(bars_reviews_value)\n",
    "bars_dataset.columns = ['Review Text','Star']\n",
    "bars_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = bars_dataset.to_csv (r'bars_dataset.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe from hotels_travel_reviews_value list which was created during the Web Scrapping and storing the data in a csv file for future use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have used this service before and was satisfied, until June 20, 2018. I prearranged via telephone a pickup from Terminal 3 to Georgetown and clearly specified a credit card would be used for payment to the driver. The car 570L arrived quickly and was clean and the drive uneventful. When it came time to pay I presented my MasterCard and that's when the problem started. The driver found he had no connection on his payment device. He tried several times to put the card throug, he even tried to put his own card through at one paint in this debacle, and each time the unit said 'no connection'. He then tried driving the car (with me in it) off my property and up and down the street in search of an internet connection, at one point he drove me to an auto repair facility up the road, stopping along the way and staying parked in the auto parking lot trying to obtain internet service. I finally asked after a very extended period to please return to my property to sort it out. It was getting dark and I was travelling alone and getting anxious. I only had a credit card in which to pay with. He proceeded to suggest that he would drive me into Georgetown to an ATM to get money. I said no to this as it would add another 20 minutes to this lengthy ordeal of being trapped in the car.i offered him a cheque which was the only other logical option. H e said no to that idea. He then proceeded to call his dispatch office and I could hear every word. They told him they could not take payments via this route as he was desperately trying to get someone to process my card payment. Then he called 'Gurdeep\", whoever that is, who told him to try charging his unit. He then spent at least 20 minutes looking over every inch of his car for his charger .....to no avail. I insisted after 45 minutes that I was leaving and going into my home and that a cheque would be the only option. He refused to leave my property. I went inside leaving him to pace around my driveway in the dark on the phone with Gurdeep. After another period of home the driver came to my door and asked me to speak to Gurdeep. I explained what was going on to Gurdeep and his impolite aggressive and rude response was that it was 'not his problem that I had no cash'.....and the problem was I lived in Halton Hills. I decided not to communicate any further with Gurdeep as he was not understanding of the situation, and of the fact that I had specified upon booking that I would be paying by credit card. The driver then told me he would call the police for non-payment, then decided after another call, and more pacing around my driveway that Gurdeep would accept my cheque. At this point I was terrified, and it was dark and I was alone. I told the driver I would have my husband (who was in another province) call the company to arrange a credit card payment. The driver still refused to leave. My husband called the company and they finally accepted his card for payment...somehow. The driver sat on the road in front of my house until the hit man Gurdeep received payment I guess. I will NEVER use this service again. It was a horrible experience. I had every intention of paying, and sincerely hope this does not happen to anyone else, especially a female travelling alone.</td>\n",
       "      <td>1-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First time I tried using them the driver was nowhere to be found. Called and found out he was still 30 minutes away! I understand there is traffic, but your job is to drive. Seriously, look/listen/read the traffic reports. Yes it may have been close to rush hour, so maybe leave a bit earlier? I've never had a problem getting to/from places outside the city on time, so I have a hard time understanding why someone who's job it is to do the same thing can't show up on time. Thought I'd give them another shot as maybe it was just a lazy/poor/uncaring driver. This time, 15 minutes before my pickup time, the driver cancels and I'm told they're finding me another vehicle. How long will that take? Don't know. Great. So I've got 15 minutes to either hail an Uber, or wait for someone to maybe show up. No problem. Should have just used Uber in the first place. In summary, if they happen to be sitting right out front and you can get a reasonable flat rate, fair enough. In any other case, use Uber/Lyft/anything else, or risk being told at the last minute that for whatever reason your car isn't showing up....</td>\n",
       "      <td>1-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Driver picked me up on time at 6AM and even knocked on my door instead of ringing my doorbell, in case people were still sleeping. Was courteous and polite the entire ride. Car was in good shape and didn't smell of smoke. Will definitely use them again!</td>\n",
       "      <td>5-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>First time using this taxi and limo company as I have used others. I was very happy with the services provided. I like the online booking and email confirmation with a reference number. I called the day I needed the limo service and the driver arrived a few minutes a head of time.</td>\n",
       "      <td>5-star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great experience. Driver was early and was very friendly. Got me there early and was a smooth driver. Car was clean and well maintained.</td>\n",
       "      <td>5-star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Review Text  \\\n",
       "0  I have used this service before and was satisfied, until June 20, 2018. I prearranged via telephone a pickup from Terminal 3 to Georgetown and clearly specified a credit card would be used for payment to the driver. The car 570L arrived quickly and was clean and the drive uneventful. When it came time to pay I presented my MasterCard and that's when the problem started. The driver found he had no connection on his payment device. He tried several times to put the card throug, he even tried to put his own card through at one paint in this debacle, and each time the unit said 'no connection'. He then tried driving the car (with me in it) off my property and up and down the street in search of an internet connection, at one point he drove me to an auto repair facility up the road, stopping along the way and staying parked in the auto parking lot trying to obtain internet service. I finally asked after a very extended period to please return to my property to sort it out. It was getting dark and I was travelling alone and getting anxious. I only had a credit card in which to pay with. He proceeded to suggest that he would drive me into Georgetown to an ATM to get money. I said no to this as it would add another 20 minutes to this lengthy ordeal of being trapped in the car.i offered him a cheque which was the only other logical option. H e said no to that idea. He then proceeded to call his dispatch office and I could hear every word. They told him they could not take payments via this route as he was desperately trying to get someone to process my card payment. Then he called 'Gurdeep\", whoever that is, who told him to try charging his unit. He then spent at least 20 minutes looking over every inch of his car for his charger .....to no avail. I insisted after 45 minutes that I was leaving and going into my home and that a cheque would be the only option. He refused to leave my property. I went inside leaving him to pace around my driveway in the dark on the phone with Gurdeep. After another period of home the driver came to my door and asked me to speak to Gurdeep. I explained what was going on to Gurdeep and his impolite aggressive and rude response was that it was 'not his problem that I had no cash'.....and the problem was I lived in Halton Hills. I decided not to communicate any further with Gurdeep as he was not understanding of the situation, and of the fact that I had specified upon booking that I would be paying by credit card. The driver then told me he would call the police for non-payment, then decided after another call, and more pacing around my driveway that Gurdeep would accept my cheque. At this point I was terrified, and it was dark and I was alone. I told the driver I would have my husband (who was in another province) call the company to arrange a credit card payment. The driver still refused to leave. My husband called the company and they finally accepted his card for payment...somehow. The driver sat on the road in front of my house until the hit man Gurdeep received payment I guess. I will NEVER use this service again. It was a horrible experience. I had every intention of paying, and sincerely hope this does not happen to anyone else, especially a female travelling alone.   \n",
       "1  First time I tried using them the driver was nowhere to be found. Called and found out he was still 30 minutes away! I understand there is traffic, but your job is to drive. Seriously, look/listen/read the traffic reports. Yes it may have been close to rush hour, so maybe leave a bit earlier? I've never had a problem getting to/from places outside the city on time, so I have a hard time understanding why someone who's job it is to do the same thing can't show up on time. Thought I'd give them another shot as maybe it was just a lazy/poor/uncaring driver. This time, 15 minutes before my pickup time, the driver cancels and I'm told they're finding me another vehicle. How long will that take? Don't know. Great. So I've got 15 minutes to either hail an Uber, or wait for someone to maybe show up. No problem. Should have just used Uber in the first place. In summary, if they happen to be sitting right out front and you can get a reasonable flat rate, fair enough. In any other case, use Uber/Lyft/anything else, or risk being told at the last minute that for whatever reason your car isn't showing up....                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "2  Driver picked me up on time at 6AM and even knocked on my door instead of ringing my doorbell, in case people were still sleeping. Was courteous and polite the entire ride. Car was in good shape and didn't smell of smoke. Will definitely use them again!                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        \n",
       "3  First time using this taxi and limo company as I have used others. I was very happy with the services provided. I like the online booking and email confirmation with a reference number. I called the day I needed the limo service and the driver arrived a few minutes a head of time.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "4  Great experience. Driver was early and was very friendly. Got me there early and was a smooth driver. Car was clean and well maintained.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             \n",
       "\n",
       "     Star  \n",
       "0  1-star  \n",
       "1  1-star  \n",
       "2  5-star  \n",
       "3  5-star  \n",
       "4  5-star  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels_travel_dataset = pd.DataFrame(hotels_travel_reviews_value)\n",
    "hotels_travel_dataset.columns = ['Review Text','Star']\n",
    "hotels_travel_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = hotels_travel_dataset.to_csv (r'hotels_travel_dataset.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data from the CSV files which was created in the above step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_dataset=pd.read_csv(\"bars_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_travel_dataset=pd.read_csv(\"hotels_travel_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Number of records in the Bars category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bars_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the Number of records in the Hotels and travel category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1430"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hotels_travel_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>This shows that all the records were successfully scrapped from the URL provided. Number of records in the dataset matches the number of reviews mentioned of the webpage</b>\n",
    "<img src=\"number_of_reviews.png\" height=300, width=300></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function which returns whether the review is “positive” or “negative” based on the star rating. For this assignment, we are assuming that 1-star to 3-star reviews are “negative”, and 4-star to 5-star reviews as “positive”. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Positive_Negative_Based_On_Stars(star_text):\n",
    "    number_of_stars=int(star_text[0])\n",
    "    if 1 <= number_of_stars <= 3:\n",
    "        return \"Negative\"\n",
    "    elif 4 <= number_of_stars <= 5:\n",
    "        return \"Postive\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a new column <b> 'class_label' </b>which classify review as \"positive\" or \"negative\" based on the star rating. In this for each value in the column 'Star', we are calling <b> Positive_Negative_Based_On_Stars function </b>, which return \"positive\" or \"negative\" value. We are then storing this value in the new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bars_dataset['class_label'] =\\\n",
    "bars_dataset['Star'].apply(lambda x: Positive_Negative_Based_On_Stars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Star</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It would help if the front girl don't just sit us down and not ask us for drinks or put us with a waitress. Instead, let us just sit here for almost an hour unattended! If it's time for you to clock out then it's not our problem. But if you're gonna seat us be more professional about it at least then leave!</td>\n",
       "      <td>3-star</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                            Review Text  \\\n",
       "0  It would help if the front girl don't just sit us down and not ask us for drinks or put us with a waitress. Instead, let us just sit here for almost an hour unattended! If it's time for you to clock out then it's not our problem. But if you're gonna seat us be more professional about it at least then leave!   \n",
       "\n",
       "     Star class_label  \n",
       "0  3-star  Negative    "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars_dataset.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing the same for hotels and travel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hotels_travel_dataset['class_label'] = \\\n",
    "hotels_travel_dataset['Star'].apply(lambda x: Positive_Negative_Based_On_Stars(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Star</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have used this service before and was satisfied, until June 20, 2018. I prearranged via telephone a pickup from Terminal 3 to Georgetown and clearly specified a credit card would be used for payment to the driver. The car 570L arrived quickly and was clean and the drive uneventful. When it came time to pay I presented my MasterCard and that's when the problem started. The driver found he had no connection on his payment device. He tried several times to put the card throug, he even tried to put his own card through at one paint in this debacle, and each time the unit said 'no connection'. He then tried driving the car (with me in it) off my property and up and down the street in search of an internet connection, at one point he drove me to an auto repair facility up the road, stopping along the way and staying parked in the auto parking lot trying to obtain internet service. I finally asked after a very extended period to please return to my property to sort it out. It was getting dark and I was travelling alone and getting anxious. I only had a credit card in which to pay with. He proceeded to suggest that he would drive me into Georgetown to an ATM to get money. I said no to this as it would add another 20 minutes to this lengthy ordeal of being trapped in the car.i offered him a cheque which was the only other logical option. H e said no to that idea. He then proceeded to call his dispatch office and I could hear every word. They told him they could not take payments via this route as he was desperately trying to get someone to process my card payment. Then he called 'Gurdeep\", whoever that is, who told him to try charging his unit. He then spent at least 20 minutes looking over every inch of his car for his charger .....to no avail. I insisted after 45 minutes that I was leaving and going into my home and that a cheque would be the only option. He refused to leave my property. I went inside leaving him to pace around my driveway in the dark on the phone with Gurdeep. After another period of home the driver came to my door and asked me to speak to Gurdeep. I explained what was going on to Gurdeep and his impolite aggressive and rude response was that it was 'not his problem that I had no cash'.....and the problem was I lived in Halton Hills. I decided not to communicate any further with Gurdeep as he was not understanding of the situation, and of the fact that I had specified upon booking that I would be paying by credit card. The driver then told me he would call the police for non-payment, then decided after another call, and more pacing around my driveway that Gurdeep would accept my cheque. At this point I was terrified, and it was dark and I was alone. I told the driver I would have my husband (who was in another province) call the company to arrange a credit card payment. The driver still refused to leave. My husband called the company and they finally accepted his card for payment...somehow. The driver sat on the road in front of my house until the hit man Gurdeep received payment I guess. I will NEVER use this service again. It was a horrible experience. I had every intention of paying, and sincerely hope this does not happen to anyone else, especially a female travelling alone.</td>\n",
       "      <td>1-star</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Review Text  \\\n",
       "0  I have used this service before and was satisfied, until June 20, 2018. I prearranged via telephone a pickup from Terminal 3 to Georgetown and clearly specified a credit card would be used for payment to the driver. The car 570L arrived quickly and was clean and the drive uneventful. When it came time to pay I presented my MasterCard and that's when the problem started. The driver found he had no connection on his payment device. He tried several times to put the card throug, he even tried to put his own card through at one paint in this debacle, and each time the unit said 'no connection'. He then tried driving the car (with me in it) off my property and up and down the street in search of an internet connection, at one point he drove me to an auto repair facility up the road, stopping along the way and staying parked in the auto parking lot trying to obtain internet service. I finally asked after a very extended period to please return to my property to sort it out. It was getting dark and I was travelling alone and getting anxious. I only had a credit card in which to pay with. He proceeded to suggest that he would drive me into Georgetown to an ATM to get money. I said no to this as it would add another 20 minutes to this lengthy ordeal of being trapped in the car.i offered him a cheque which was the only other logical option. H e said no to that idea. He then proceeded to call his dispatch office and I could hear every word. They told him they could not take payments via this route as he was desperately trying to get someone to process my card payment. Then he called 'Gurdeep\", whoever that is, who told him to try charging his unit. He then spent at least 20 minutes looking over every inch of his car for his charger .....to no avail. I insisted after 45 minutes that I was leaving and going into my home and that a cheque would be the only option. He refused to leave my property. I went inside leaving him to pace around my driveway in the dark on the phone with Gurdeep. After another period of home the driver came to my door and asked me to speak to Gurdeep. I explained what was going on to Gurdeep and his impolite aggressive and rude response was that it was 'not his problem that I had no cash'.....and the problem was I lived in Halton Hills. I decided not to communicate any further with Gurdeep as he was not understanding of the situation, and of the fact that I had specified upon booking that I would be paying by credit card. The driver then told me he would call the police for non-payment, then decided after another call, and more pacing around my driveway that Gurdeep would accept my cheque. At this point I was terrified, and it was dark and I was alone. I told the driver I would have my husband (who was in another province) call the company to arrange a credit card payment. The driver still refused to leave. My husband called the company and they finally accepted his card for payment...somehow. The driver sat on the road in front of my house until the hit man Gurdeep received payment I guess. I will NEVER use this service again. It was a horrible experience. I had every intention of paying, and sincerely hope this does not happen to anyone else, especially a female travelling alone.   \n",
       "\n",
       "     Star class_label  \n",
       "0  1-star  Negative    "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels_travel_dataset.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Star</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>637</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>793</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Review Text  Star\n",
       "class_label                   \n",
       "Negative     637          637 \n",
       "Postive      793          793 "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hotels_travel_dataset.groupby(['class_label']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Star</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>565</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>895</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Review Text  Star\n",
       "class_label                   \n",
       "Negative     565          565 \n",
       "Postive      895          895 "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bars_dataset.groupby(['class_label']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "For both category datasets: <br>\n",
    "a. From the reviews in this category, apply appropriate preprocessing steps to\n",
    "create a numeric representation of the data, suitable for classification.<br>\n",
    "b. Build a classification model using a classifier of your choice, to distinguish\n",
    "between “positive” and “negative” reviews.<br>\n",
    "c. Test the predictions of the classification model using an appropriate\n",
    "evaluation strategy. Report and discuss the evaluation results in your\n",
    "notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category 1 - Hotels and travel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we just need two columns 'Review Text' and 'class_label'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=hotels_travel_dataset['Review Text'].values\n",
    "Y=hotels_travel_dataset['class_label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to split the data in <b>training</b> and <b>test dataset</b>. Training dataset is used to train the model and create the document-term matrix. We are also using it to perform <b> parameter tuning </b> of the model. Once we have our model ready, we are predicting the values on the test dataset to find the accuracy and to create a confusion matrix. We are splitting the data into 70% training set and 30% test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents, test_documents, train_target, test_target = train_test_split(X, Y, random_state=0,\\\n",
    "                                                                              train_size = 0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are then transforming our list of Review text into a document-term matrix by applying some pre-processing steps. We are using <b>TF-IDF </b>for weighting the score for a term in a document. In this way we are improving the usefulness of the document-term matrix as this will give higher weights to more important terms by looking at the inverse document frequency(total number of distinct documents containing a term), along with term frequency.     \n",
    "\n",
    "Pre-processing steps performed to create a numeric representation of the data are-\n",
    "\n",
    "1) <b>Minimum term length</b>: Excluding terms of length < 2. Scikit-learn does this by default. <br>\n",
    "2) <b>Case conversion</b>: Converting all terms to lowercase. Scikit-learn does this by default.<br>\n",
    "3)<b> Stop-word filtering</b>: It involves removing terms which  appear frequently but doesn't convey useful information. We have handled this in our custom tokenizer function (lemma_tokenizer).<br>\n",
    "4) <b>Low frequency filtering</b>: Remove terms that appear in very few documents. In our case we have set min_df to 3. This means that the world should be present in atleast 3 documents to be considered in document-term matrix.<br>\n",
    "5) <b>Lemmatisation</b>- It is a process of reducing a word to its canonical form. We have handled this in our custom tokenizer function (lemma_tokenizer)<br>\n",
    "\n",
    "<b>lemma_tokenizer(text)</b> - This is the common function which will be used to tokenize the text, which is the first step in analysing documents. It is used to split the raw text into individual tokens, each corresponding to a single word. This function takes the input text and creates tokens using CountVectorizer(). Then with the help of WordNetLemmatizer object we perform Lemmatization. We have also created a set of stopwords. For each token, we check if that word is a stopword or not. If it is not a stopword, then we lemmatize that word and append the result in the list otherwise we skip that word. At the end we will have a list which contains the lemmatized version of the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function used to handle Lemmatisation and Stopwords removal\n",
    "def lemma_tokenizer(text):\n",
    "    # use the standard scikit-learn tokenizer first\n",
    "    standard_tokenizer = CountVectorizer().build_tokenizer()\n",
    "    tokens = standard_tokenizer(text)\n",
    "    # then use NLTK to perform lemmatisation on each token\n",
    "    lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "    lemma_tokens = []\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            lemma_tokens.append( lemmatizer.lemmatize(token) )\n",
    "    return lemma_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using <b>TfidfVectorizer</b> function of sklearn we will create a document-term matrix on train_document. Inside this function we have specified the pre-processing steps it should consider. We have set min_df=3 and have passed a custom tokenizer to handle lemmatisation and stop words removal. It converts text to lowercase and excludes terms of length <2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5100)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 3,tokenizer=lemma_tokenizer,ngram_range=(1, 2))\n",
    "train_data_X = vectorizer.fit_transform(train_documents)\n",
    "print(train_data_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our document-term matrix ready. We have created a numeric representation of the data that is suitable for classification. It will be used to train our model. And also our test documents will use the same vocabulary which is created above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 5100)\n"
     ]
    }
   ],
   "source": [
    "test_data_X = vectorizer.transform(test_documents)\n",
    "print(test_data_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have create document-term matrix from test documents by calling transform() method to use the same vocabulary as the of training dataset. We will use text_X in the below models for testing purpose. It will be used when we are testing for Simple Hold Out Approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For <b>cross-validation</b> we need document term matrix on entire dataset. In that approach we are not dividing our dataset in training and testing. Following steps are performed for K-Fold Cross Validation :- \n",
    "\n",
    "1. We first divide our data into k disjoint subsets known as “folds”<br/>\n",
    "2. Then for each of k experiments, we use k-1 folds for training and the\n",
    "selected one fold for testing <br/>\n",
    "3. We repeat this process for all k folds and at the end we find the average accuracy rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1430, 7011)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_dataset = TfidfVectorizer(min_df = 3,tokenizer=lemma_tokenizer)\n",
    "dataset_X = vectorizer.fit_transform(X)\n",
    "print(dataset_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a classification model using a classifier of your choice, to distinguish between “positive” and “negative” reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_testdata_accuracy_comparisons = dict()\n",
    "model_testdata_f1_comparisons=dict()\n",
    "model_cross_validation_accuracy_comparisons = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used k-nearest neighbors to perfrom the classification. In this we look at the k nearest neighbour to find out the label for new instance. First I have created the mdoel where value of K=3. First I am using simple hold out approach to perform the evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(train_data_X, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8251748251748252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.82      0.78      0.80       194\n",
      "     Postive       0.83      0.86      0.84       235\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       429\n",
      "   macro avg       0.82      0.82      0.82       429\n",
      "weighted avg       0.83      0.83      0.82       429\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>152</td>\n",
       "      <td>42</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>33</td>\n",
       "      <td>202</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>185</td>\n",
       "      <td>244</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   152       42       194\n",
       "Postive    33        202      235\n",
       "All        185       244      429"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = model.predict(test_data_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target, y_pred) # , normalize=True, sample_weight=None\n",
    "model_testdata_accuracy_comparisons[\"KNN(K=3)\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_target, y_pred))\n",
    "report = metrics.classification_report(test_target, y_pred)\n",
    "model_testdata_f1_comparisons[\"KNN(K=3)\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting 82.5% accuracy by performing simple hold out approach. In this model we have set value of k=3. But we can perform some parameter tuning to improve the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hyper Parameters Tuning of KNN model using Grid Search </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the parameter values that should be tuned. In our case we want to find the best value of k in the range of 1 to 20. We create a parameter grid which maps the parameter names to the values that should be searched. It is a dictionary where key is the parameter name and value is the list of values that should be searched for that parameter. Then we instatiate the Grid by specifying the model, parameter grid, number of fold to perform cross validation and what scoring should be use to find the best parameter. We are using training dataset to perform the hyper parameter tuning of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_range = list(range(1, 20))\n",
    "param_grid = dict(n_neighbors=k_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(KNeighborsClassifier(metric='cosine'), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(train_data_X, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 13}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.844"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print details\n",
    "print(\"Best parameters set found on training set:\")\n",
    "display(grid.best_params_)\n",
    "display(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above results that when k=13, we get the best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the best parameters to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=13, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate model with best parameters\n",
    "knn = KNeighborsClassifier(n_neighbors=13, metric='cosine')\n",
    "knn.fit(train_data_X, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making <b>predictions</b> on the <b>test dataset</b> and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier\n",
    "performance. Below are the interpretation of the terms in confusion matrix according to our problem statement.\n",
    "<ul>\n",
    "    <li>TP = Positive Review correctly predicted as Positive </li>\n",
    "    <li>FP = Negative Review incorrectly predicted as Postive</li>\n",
    "    <li>TN = Negative Review correctly predicted as Negative</li>\n",
    "    <li>FN = Positive Review incorrectly predicted as Negative </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8461538461538461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.83      0.82      0.83       194\n",
      "     Postive       0.86      0.86      0.86       235\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       429\n",
      "   macro avg       0.84      0.84      0.84       429\n",
      "weighted avg       0.85      0.85      0.85       429\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>160</td>\n",
       "      <td>34</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>32</td>\n",
       "      <td>203</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>192</td>\n",
       "      <td>237</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   160       34       194\n",
       "Postive    32        203      235\n",
       "All        192       237      429"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = knn.predict(test_data_X)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target, y_pred) # , normalize=True, sample_weight=None\n",
    "model_testdata_accuracy_comparisons[\"KNN(K=13)\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_target, y_pred))\n",
    "report = metrics.classification_report(test_target, y_pred)\n",
    "model_testdata_f1_comparisons[\"KNN(K=13)\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting 84.6% accuracy by performing simple hold out approach on the tuned model. In this model we have set value of k=14."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use <b>Cross-Validation</b> to measure the performance of the classifier. A problem with simpe random splitting of dataset into two sets is that each random split might give different results. So we can use cross-validation to evaluate the model. In this we are using the tuned KNN model to perform the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_knn = KNeighborsClassifier(n_neighbors=13, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82926829 0.81533101 0.84265734 0.7754386  0.85614035]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tuned_knn, dataset_X,Y, cv=5, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8237671186323304"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cross_validation_accuracy_comparisons[\"KNN(K=14)\"] = scores.mean()\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>82.3% </b>accuracy with KNN Classifier when we are using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other classifiers that can be used to classify reviews as Positive and Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes Classifier- \n",
    "In this the classification is based on term frequency counts. It incorrectly assumes all terms are independent, but can still be effective in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a model and train it with the help of training dataset. We are using document-term matrix which was created above to train the model. Then we are using test documents for predictions. Again we are using document-term matrix for test documents which was created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(train_data_X, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction and finding the accuracy score and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8694638694638694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.89      0.81      0.85       194\n",
      "     Postive       0.85      0.92      0.89       235\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       429\n",
      "   macro avg       0.87      0.86      0.87       429\n",
      "weighted avg       0.87      0.87      0.87       429\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>157</td>\n",
       "      <td>37</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>19</td>\n",
       "      <td>216</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>176</td>\n",
       "      <td>253</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   157       37       194\n",
       "Postive    19        216      235\n",
       "All        176       253      429"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nb_model.predict(test_data_X)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target, y_pred) # , normalize=True, sample_weight=None\n",
    "model_testdata_accuracy_comparisons[\"Naive Bayes\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_target, y_pred))\n",
    "report = metrics.classification_report(test_target, y_pred)\n",
    "model_testdata_f1_comparisons[\"Naive Bayes\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>86.9% accuracy </b>with <b>Naive Bayes Classifier </b> when using Hold-out strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use <b>Cross-Validation</b> to measure the performance of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_cross_validation = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88501742 0.86062718 0.84615385 0.87368421 0.90526316]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(nb_model_cross_validation, dataset_X,Y, cv=5, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.874149162775607"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cross_validation_accuracy_comparisons[\"Naive Bayes\"] = scores.mean()\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>87.4% </b>accuracy with Naive Bayes Classifier when we are using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SVMs with a linear kernel to calculate document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a model and train it with the help of training dataset. We are using document-term matrix which was created above to train the model. Then we are using test documents for predictions. Again we are using document-term matrix for test documents which was created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(train_data_X, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction and finding the accuracy score and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8951048951048951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.85      0.88       194\n",
      "     Postive       0.88      0.93      0.91       235\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       429\n",
      "   macro avg       0.90      0.89      0.89       429\n",
      "weighted avg       0.90      0.90      0.89       429\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>165</td>\n",
       "      <td>29</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>16</td>\n",
       "      <td>219</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>181</td>\n",
       "      <td>248</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   165       29       194\n",
       "Postive    16        219      235\n",
       "All        181       248      429"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model.predict(test_data_X)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target, y_pred) # , normalize=True, sample_weight=None\n",
    "model_testdata_accuracy_comparisons[\"SVM (linear kernel)\"] = accuracy\n",
    "print(\"Accuracy: \" +  str(accuracy))\n",
    "print(metrics.classification_report(test_target, y_pred))\n",
    "report = metrics.classification_report(test_target, y_pred)\n",
    "model_testdata_f1_comparisons[\"SVM (linear kernel)\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>89.5% accuracy</b> with <b>SVM Classifier </b> when using Hold-out strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use <b>Cross-Validation</b> to measure the performance of the classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_cross_validation = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.90243902 0.88501742 0.89160839 0.88070175 0.8877193 ]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svc_model_cross_validation, dataset_X,Y, cv=5, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8894971780466003"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cross_validation_accuracy_comparisons[\"SVM (linear kernel)\"] = scores.mean()\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>88.9% </b>accuracy with SVM Classifier when we are using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Evaluation \n",
    "<a id=\"task_2_1\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have build three classification model to distinguish between “positive” and “negative” reviews <br/>\n",
    "1) K-Nearest Neighbour (KNN) <br/>\n",
    "2) Naive Bayes <br/>\n",
    "3) Support Vector Machine (SVM) <br/>\n",
    "\n",
    "For evaluation purpose, I have used two two strategies </br>\n",
    "\n",
    "1) <b>Hold Out Approach </b>- In this we split the data into training and testing dataset. We have used 70-30 split, which means 70% will be used to train the model and 30% will be used to test the model. One of the disadvantage of this approach is that evaluation score is dependent on how the data is splitted into train and test dataset  <br/> \n",
    "\n",
    "2) <b>5-Fold Cross Validation </b>- In this we split the dataset into 5 folds. We perform five experiments in which one selected fold is used to test the dataset and remaining 4 fold is used to train the model. We repeat this process for all the five experiments. Cross-validation will give our models the opportunity to train on multiple train-test splits. This will give us a better indication of how well our model will perform on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Results of the classification models using Hold Out Approach</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Accuracy Comparison</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy on Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN(K=3)</td>\n",
       "      <td>0.825175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN(K=13)</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.869464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (linear kernel)</td>\n",
       "      <td>0.895105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Accuracy on Test Data\n",
       "0  KNN(K=3)             0.825175             \n",
       "1  KNN(K=13)            0.846154             \n",
       "2  Naive Bayes          0.869464             \n",
       "3  SVM (linear kernel)  0.895105             "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_testdata_accuracy_comparisons.items()), columns=['Model Name', 'Accuracy on Test Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = model_testdata_accuracy_comparisons.keys()\n",
    "x_position = np.arange(len(classifiers))\n",
    "accuracy_values = model_testdata_accuracy_comparisons.values()\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x_position, accuracy_values, align='center', width=0.6, color= ['#003f5c', '#7a5195', '#ef5675', '#ffa600'])\n",
    "plt.xticks(x_position, classifiers)\n",
    "plt.xlabel('Models', fontsize='13')\n",
    "plt.ylabel('Accuracy', fontsize='13')\n",
    "plt.ylim(0.8, 1)\n",
    "plt.title('Accuracy Vs Models',fontsize='13')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>F1 Score Comparison </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Score on Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN(K=3)</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN(K=13)</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (linear kernel)</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name F1 Score on Test Data\n",
       "0  KNN(K=3)             0.82                \n",
       "1  KNN(K=13)            0.85                \n",
       "2  Naive Bayes          0.87                \n",
       "3  SVM (linear kernel)  0.89                "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_testdata_f1_comparisons.items()), columns=['Model Name', 'F1 Score on Test Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = model_testdata_f1_comparisons.keys()\n",
    "x_position = np.arange(len(classifiers))\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x_position, [float(x) for x in model_testdata_f1_comparisons.values()], align='center', width=0.6, color= ['#003f5c', '#7a5195', '#ef5675', '#ffa600'])\n",
    "plt.xticks(x_position, classifiers)\n",
    "plt.xlabel('Models', fontsize='13')\n",
    "plt.ylabel('F1-Score', fontsize='13')\n",
    "plt.ylim(0.8, 1)\n",
    "plt.title('F1-Score Vs Models',fontsize='13')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Results of the classification models using 5-Fold Cross Validation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Accuracy using Cross Va;idation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN(K=14)</td>\n",
       "      <td>0.823767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.874149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (linear kernel)</td>\n",
       "      <td>0.889497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Mean Accuracy using Cross Va;idation\n",
       "0  KNN(K=14)            0.823767                            \n",
       "1  Naive Bayes          0.874149                            \n",
       "2  SVM (linear kernel)  0.889497                            "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(model_cross_validation_accuracy_comparisons.items()), columns=['Model Name', 'Mean Accuracy using Cross Va;idation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = model_cross_validation_accuracy_comparisons.keys()\n",
    "x_position = np.arange(len(classifiers))\n",
    "accuracy_values = model_cross_validation_accuracy_comparisons.values()\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x_position, accuracy_values, align='center', width=0.6, color= ['#003f5c', '#7a5195', '#ef5675', '#ffa600'])\n",
    "plt.xticks(x_position, classifiers)\n",
    "plt.xlabel('Models', fontsize='13')\n",
    "plt.ylabel('Mean Accuracy', fontsize='13')\n",
    "plt.ylim(0.8, 1)\n",
    "plt.title('Mean Accuracy Vs Models',fontsize='13')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b>\n",
    "1. Using Simple Hold Out Approach, if we use KNN with K=3 and cosine similarity metric, then we are getting 82.5% accuracy. After fine tuning the performance of KNN, we were able to get 84.6% Accuracy. We are only tuning the value of K, but we can tune other parameters also. <br/>\n",
    "2. Naive Bayes incorrectly assumes that all terms are independent, but we can see that it is still very effective. We are getting better accuracy (86.9%) than KNN. <br/>\n",
    "3. SVM is giving us the best accuracy of 89.5% on Hotels and Travels Dataset.  <br/>\n",
    "4. If we look at F1 scores, we can see similar results. SVM giving us the best result with value 0.89. Followed by Naive Bayes (0.87) and then KKN(0.85)  <br/>\n",
    "5. Also, using Cross Validation, we are seeing similar results. SVM with linear kernel is giving us highest mean accuracy of 88.9%, followed by Naive Bayes (87.4%) and then KNN. <br/>\n",
    "6. One of the reason why we are getting high accuracy with SVM is that generally text analysis involves high dimensionality data. And there is some sort of relationship between them. Naive Bayes assumes that all the features are independent but SVM considers the dependency between the features also. That's why it takes more time to train as compared to Naive Bayes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category 2 - Bars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this task, we just need two columns 'Review Text' and 'class_label' of bars dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bars=bars_dataset['Review Text']\n",
    "Y_bars=bars_dataset['class_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to split the data in training and test dataset. Training dataset is used to train the model and create the document-term matrix. We are also using it to perform parameter tuning of the model. Once we have our model ready, we are predicting the values on the test dataset to find the accuracy and to create a confusion matrix. We are splitting the data into 70% training set and 30% test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents, test_documents, train_target, test_target = train_test_split(X_bars, Y_bars, random_state=0,\\\n",
    "                                                                              train_size = 0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TfidfVectorizer function of sklearn we will create a document-term matrix on train_document. Inside this function we have specified the pre-processing steps it should consider. We have set min_df=3 and have passed a custom tokenizer to handle lemmatisation and stop words removal. It converts text to lowercase and excludes terms of length <2. We have used the same approach that we have followed in above part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1021, 4331)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 3,tokenizer=lemma_tokenizer,ngram_range=(1, 2))\n",
    "train_data_bars = vectorizer.fit_transform(train_documents)\n",
    "print(train_data_bars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our document-term matrix ready. We have created a numeric representation of the data that is suitable for classification. It will be used to train our model. And also our test documents will use the same vocabulary which is created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(438, 4331)\n"
     ]
    }
   ],
   "source": [
    "test_data_bars = vectorizer.transform(test_documents)\n",
    "print(test_data_bars.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created document-term matrix from test documents by calling transform() method to use the same vocabulary as the of training dataset. We will use text_X in the below models for testing purpose. It will be used when we are testing for Simple Hold Out Approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For <b>cross-validation</b> we need document term matrix on entire dataset. In that approach we are not dividing our dataset in training and testing. Following steps are performed for K-Fold Cross Validation :- \n",
    "\n",
    "1. We first divide our data into k disjoint subsets known as “folds”<br/>\n",
    "2. Then for each of k experiments, we use k-1 folds for training and the\n",
    "selected one fold for testing <br/>\n",
    "3. We repeat this process for all k folds and at the end we find the average accuracy rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 6121)\n"
     ]
    }
   ],
   "source": [
    "vectorizer_dataset_Health_Medical = TfidfVectorizer(min_df = 3,tokenizer=lemma_tokenizer)\n",
    "bars_dataset_X = vectorizer.fit_transform(X_bars)\n",
    "print(bars_dataset_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a classification model using a classifier of your choice, to distinguish between “positive” and “negative” reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "category2_model_testdata_accuracy_comparisons = dict()\n",
    "category2_model_testdata_f1_comparisons = dict()\n",
    "category2_model_cross_validation_accuracy_comparisons = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have used k-nearest neighbors to perform the classification. In this we look at the k nearest neighbour to find out the label for new instance. First I have created the mdoel where value of K=3 and using simple hold out approach to perform the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='cosine',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3,metric='cosine')\n",
    "# build a model on the document-term matrix created from the training dataset\n",
    "model.fit(train_data_bars,train_target)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.62      0.66      0.64       146\n",
      "     Postive       0.82      0.80      0.81       292\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       438\n",
      "   macro avg       0.72      0.73      0.72       438\n",
      "weighted avg       0.76      0.75      0.75       438\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>96</td>\n",
       "      <td>50</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>59</td>\n",
       "      <td>233</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>155</td>\n",
       "      <td>283</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   96        50       146\n",
       "Postive    59        233      292\n",
       "All        155       283      438"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = model.predict(test_data_bars)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target, y_pred) # , normalize=True, sample_weight=None\n",
    "category2_model_testdata_accuracy_comparisons[\"KNN(K=3)\"] = accuracy\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target, y_pred))\n",
    "\n",
    "report = metrics.classification_report(test_target, y_pred)\n",
    "category2_model_testdata_f1_comparisons[\"KNN(K=3)\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting 75% accuracy by performing simple hold out approach. In this model we have set value of k=3. But we can perform some parameter tuning to improve the performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hyper Parameters Tuning of KNN model using Grid Search </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we define the parameter values that should be tuned. In our case we want to find the best value of k in the range of 1 to 20. We create a parameter grid which maps the parameter names to the values that should be searched. It is a dictionary where key is the parameter name and value is the list of values that should be searched for that parameter. Then we instatiate the Grid by specifying the model, parameter grid, number of fold to perform cross validation and what scoring should be use to find the best parameter. We are using training dataset to perform the hyper parameter tuning of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]}\n"
     ]
    }
   ],
   "source": [
    "k_range = list(range(1, 20))\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(KNeighborsClassifier(metric='cosine'), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(train_data_bars, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 14}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8109696376101861"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print details\n",
    "print(\"Best parameters set found on training set:\")\n",
    "display(grid.best_params_)\n",
    "display(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the above results that when k=14, we get the best accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the best parameters to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='cosine',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=14, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=14, metric='cosine')\n",
    "knn.fit(train_data_bars, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.72      0.71      0.71       146\n",
      "     Postive       0.85      0.86      0.86       292\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       438\n",
      "   macro avg       0.79      0.78      0.79       438\n",
      "weighted avg       0.81      0.81      0.81       438\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>103</td>\n",
       "      <td>43</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>40</td>\n",
       "      <td>252</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>143</td>\n",
       "      <td>295</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   103       43       146\n",
       "Postive    40        252      292\n",
       "All        143       295      438"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a set of predictions for the test data\n",
    "y_pred = knn.predict(test_data_bars)\n",
    "\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target, y_pred) # , normalize=True, sample_weight=None\n",
    "category2_model_testdata_accuracy_comparisons[\"KNN(K=14)\"] = accuracy\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target, y_pred))\n",
    "\n",
    "report = metrics.classification_report(test_target, y_pred)\n",
    "category2_model_testdata_f1_comparisons[\"KNN(K=14)\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>81% accuracy </b>with <b>KNN classifier </b> when using Hold-out strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use <b>Cross-Validation</b> to measure the performance of the classifier. In this we are using the tuned KNN model to perform the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_knn = KNeighborsClassifier(n_neighbors=14, metric='cosine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82191781 0.78082192 0.73287671 0.80479452 0.78424658]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(tuned_knn, bars_dataset_X,Y_bars, cv=5, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7849315068493151"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category2_model_cross_validation_accuracy_comparisons[\"KNN(K=10)\"] = scores.mean()\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>78.4% </b>accuracy with KNN Classifier when we are using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other classifiers that can be used to classify reviews as Positive and Negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Naive Bayes Classifier- \n",
    "In this the classification is based on term frequency counts. It incorrectly assumes all terms are independent, but can still be effective in practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we created a naive bayes model and train it with the help of training dataset. We are then using document-term matrix which we have created above to train the model. Then we are using test documents to make predictions. Again we are using document-term matrix for test documents which was created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(train_data_bars, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction and finding the accuracy score and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.61      0.72       146\n",
      "     Postive       0.83      0.96      0.89       292\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       438\n",
      "   macro avg       0.86      0.78      0.81       438\n",
      "weighted avg       0.85      0.84      0.83       438\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>89</td>\n",
       "      <td>57</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>12</td>\n",
       "      <td>280</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>101</td>\n",
       "      <td>337</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   89        57       146\n",
       "Postive    12        280      292\n",
       "All        101       337      438"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = nb_model.predict(test_data_bars)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target, y_pred) # , normalize=True, sample_weight=None\n",
    "category2_model_testdata_accuracy_comparisons[\"Naive Bayes\"] = accuracy\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target, y_pred))\n",
    "\n",
    "report = metrics.classification_report(test_target, y_pred)\n",
    "category2_model_testdata_f1_comparisons[\"Naive Bayes\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>84% accuracy </b>with <b>Naive Bayes Classifier </b> when using Hold-out strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use <b>Cross-Validation</b> to measure the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_cross_validation = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85616438 0.80136986 0.81164384 0.83561644 0.79794521]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(nb_model_cross_validation, bars_dataset_X,Y_bars, cv=5, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8205479452054796"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category2_model_cross_validation_accuracy_comparisons[\"Naive Bayes\"] = scores.mean()\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>82.0% </b>accuracy with Naive Bayes Classifier when we are using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. SVMs with a linear kernel to calculate document similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we create a svm model and train it with the help of training dataset. We are using document-term matrix which was created above to train the model. Then we are using test documents for predictions. Again we are using document-term matrix for test documents which was created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(train_data_bars, train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction and finding the accuracy score and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.76      0.78       146\n",
      "     Postive       0.88      0.90      0.89       292\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       438\n",
      "   macro avg       0.84      0.83      0.84       438\n",
      "weighted avg       0.85      0.86      0.86       438\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>111</td>\n",
       "      <td>35</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>28</td>\n",
       "      <td>264</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>139</td>\n",
       "      <td>299</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   111       35       146\n",
       "Postive    28        264      292\n",
       "All        139       299      438"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model.predict(test_data_bars)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target, y_pred) # , normalize=True, sample_weight=None\n",
    "category2_model_testdata_accuracy_comparisons[\"SVM (linear kernel)\"] = accuracy\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target, y_pred))\n",
    "\n",
    "report = metrics.classification_report(test_target, y_pred)\n",
    "category2_model_testdata_f1_comparisons[\"SVM (linear kernel)\"] = report.split('\\n')[-2].split('      ')[3]\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>86% accuracy</b> with <b>SVM Classifier </b> when using Hold-out strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use <b>Cross-Validation</b> to measure the performance of the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model_cross_validation = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89383562 0.80821918 0.85616438 0.84246575 0.87328767]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(svc_model_cross_validation, bars_dataset_X,Y_bars, cv=5, scoring=\"accuracy\")\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8547945205479452"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "category2_model_cross_validation_accuracy_comparisons[\"SVM (linear kernel)\"] = scores.mean()\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting <b>85.4% </b>accuracy with SVM Classifier when we are using Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Evaluation \n",
    "<a id=\"task_2_2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have build three classification model to distinguish between “positive” and “negative” reviews <br/>\n",
    "1) K-Nearest Neighbour (KNN) <br/>\n",
    "2) Naive Bayes <br/>\n",
    "3) Support Vector Machine (SVM) <br/>\n",
    "\n",
    "For evaluation purpose, I have used two two strategies </br>\n",
    "\n",
    "1) <b>Hold Out Approach </b>- In this we split the data into training and testing dataset. We have used 70-30 split, which means 70% will be used to train the model and 30% will be used to test the model. One of the disadvantage of this approach is that evaluation score is dependent on how the data is splitted into train and test dataset  <br/> \n",
    "\n",
    "2) <b>5-Fold Cross Validation </b>- In this we split the dataset into 5 folds. We perform five experiments in which one selected fold is used to test the dataset and remaining 4 fold is used to train the model. We repeat this process for all the five experiments. Cross-validation will give our models the opportunity to train on multiple train-test splits. This will give us a better indication of how well our model will perform on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Results of the classification models using Hold Out Approach</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Model Accuracy Comparison</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Accuracy on Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN(K=3)</td>\n",
       "      <td>0.751142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN(K=14)</td>\n",
       "      <td>0.810502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.842466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (linear kernel)</td>\n",
       "      <td>0.856164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Accuracy on Test Data\n",
       "0  KNN(K=3)             0.751142             \n",
       "1  KNN(K=14)            0.810502             \n",
       "2  Naive Bayes          0.842466             \n",
       "3  SVM (linear kernel)  0.856164             "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(category2_model_testdata_accuracy_comparisons.items()), columns=['Model Name', 'Accuracy on Test Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = category2_model_testdata_accuracy_comparisons.keys()\n",
    "x_position = np.arange(len(classifiers))\n",
    "accuracy_values = category2_model_testdata_accuracy_comparisons.values()\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x_position, accuracy_values, align='center', width=0.6, color= ['#003f5c', '#7a5195', '#ef5675', '#ffa600'])\n",
    "plt.xticks(x_position, classifiers)\n",
    "plt.xlabel('Models', fontsize='13')\n",
    "plt.ylabel('Accuracy', fontsize='13')\n",
    "plt.ylim(0.7, 1)\n",
    "plt.title('Accuracy Vs Models',fontsize='13')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>F1 Score Comparison </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>F1 Score on Test Data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN(K=3)</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN(K=14)</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM (linear kernel)</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name F1 Score on Test Data\n",
       "0  KNN(K=3)             0.75                \n",
       "1  KNN(K=14)            0.81                \n",
       "2  Naive Bayes          0.83                \n",
       "3  SVM (linear kernel)  0.86                "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(category2_model_testdata_f1_comparisons.items()), columns=['Model Name', 'F1 Score on Test Data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = category2_model_testdata_f1_comparisons.keys()\n",
    "x_position = np.arange(len(classifiers))\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x_position, [float(x) for x in category2_model_testdata_f1_comparisons.values()], align='center', width=0.6, color= ['#003f5c', '#7a5195', '#ef5675', '#ffa600'])\n",
    "plt.xticks(x_position, classifiers)\n",
    "plt.xlabel('Models', fontsize='13')\n",
    "plt.ylabel('F1-Score', fontsize='13')\n",
    "plt.ylim(0.7, 1)\n",
    "plt.title('F1-Score Vs Models',fontsize='13')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Results of the classification models using 5-Fold Cross Validation</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Mean Accuracy using Cross Va;idation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN(K=10)</td>\n",
       "      <td>0.784932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.820548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVM (linear kernel)</td>\n",
       "      <td>0.854795</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model Name  Mean Accuracy using Cross Va;idation\n",
       "0  KNN(K=10)            0.784932                            \n",
       "1  Naive Bayes          0.820548                            \n",
       "2  SVM (linear kernel)  0.854795                            "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(list(category2_model_cross_validation_accuracy_comparisons.items()), columns=['Model Name', 'Mean Accuracy using Cross Va;idation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifiers = category2_model_cross_validation_accuracy_comparisons.keys()\n",
    "x_position = np.arange(len(classifiers))\n",
    "accuracy_values = category2_model_cross_validation_accuracy_comparisons.values()\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.bar(x_position, accuracy_values, align='center', width=0.6, color= ['#7a5195', '#ef5675', '#ffa600'])\n",
    "plt.xticks(x_position, classifiers)\n",
    "plt.xlabel('Models', fontsize='13')\n",
    "plt.ylabel('Mean Accuracy', fontsize='13')\n",
    "plt.ylim(0.7, 1)\n",
    "plt.title('Mean Accuracy Vs Models',fontsize='13')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation</b>\n",
    "1. Using Simple Hold Out Approach, if we use KNN with K=3 and cosine similarity metric, then we are getting 75.1% accuracy. After fine tuning the performance of KNN, we were able to get 81.0% Accuracy. We are only tuning the value of K, but we can tune other parameters also. <br/>\n",
    "2. Naive Bayes incorrectly assumes that all terms are independent, but we can see that it is still very effective. We are getting better accuracy (84.2%) than KNN. <br/>\n",
    "3. SVM is giving us the best accuracy of 85.6% on Bars Dataset.  <br/>\n",
    "4. If we look at F1 scores, we can see similar results. SVM giving us the best result with value 0.86. Followed by Naive Bayes (0.83) and then KKN(0.81)  <br/>\n",
    "5. Also, using Cross Validation, we are seeing similar results. SVM with linear kernel is giving us highest mean accuracy of 85.4%, followed by Naive Bayes (82.0%) and then KNN (85.4%). <br/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "\n",
    "Evaluate how well your two classification models transfer between category.\n",
    "That is, run experiments to: <br/>\n",
    "a. Train a classification model on the data from “Category A”, and evaluate its\n",
    "performance on the data from “Category B”.<br/>\n",
    "b. Train a classification model on the data from “Category B”, and evaluate its\n",
    "performance on the data from “Category A”. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1\n",
    "Train a classification model on the data from “Category A”, and evaluate its performance on the data from “Category B”.<br/>\n",
    "In our case Category 1 is bars and Category 2 is Hotels and Travel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category A\n",
    "train_documents=bars_dataset['Review Text']\n",
    "train_target=bars_dataset['class_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are splitting the data in training and testing. Testing data would be used to evalaute the model trained on same category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents_category_A, test_documents_category_A, train_target_category_A, test_target_category_A \\\n",
    "= train_test_split(train_documents, train_target, random_state=0,train_size = 0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would be using this data to evalaute the model trained on different category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category B (Test Dataset for Category B)\n",
    "test_documents_category_B=hotels_travel_dataset['Review Text']\n",
    "test_target_category_B=hotels_travel_dataset['class_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1021, 4331)\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = CountVectorizer(stop_words=\"english\",min_df = 3,tokenizer=lemma_tokenizer)\n",
    "vectorizer = TfidfVectorizer(min_df = 3,tokenizer=lemma_tokenizer,ngram_range=(1, 2))\n",
    "train_X = vectorizer.fit_transform(train_documents_category_A)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector for test documents of same category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(438, 4331)\n"
     ]
    }
   ],
   "source": [
    "test_X_category_A = vectorizer.transform(test_documents_category_A)\n",
    "print(test_X_category_A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector for test documents from different category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1430, 4331)\n"
     ]
    }
   ],
   "source": [
    "test_X_category_B = vectorizer.transform(test_documents_category_B)\n",
    "print(test_X_category_B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous part, we saw that <b>SVM model</b> was giving us the best accuracy. So we will use that model to evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(train_X, train_target_category_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the same category test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.80      0.76      0.78       146\n",
      "     Postive       0.88      0.90      0.89       292\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       438\n",
      "   macro avg       0.84      0.83      0.84       438\n",
      "weighted avg       0.85      0.86      0.86       438\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>111</td>\n",
       "      <td>35</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>28</td>\n",
       "      <td>264</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>139</td>\n",
       "      <td>299</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   111       35       146\n",
       "Postive    28        264      292\n",
       "All        139       299      438"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model.predict(test_X_category_A)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target_category_A, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target_category_A, y_pred))\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target_category_A, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the different category test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.74      0.79       637\n",
      "     Postive       0.81      0.90      0.85       793\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1430\n",
      "   macro avg       0.83      0.82      0.82      1430\n",
      "weighted avg       0.83      0.82      0.82      1430\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>469</td>\n",
       "      <td>168</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>83</td>\n",
       "      <td>710</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>552</td>\n",
       "      <td>878</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive   All\n",
       "True                              \n",
       "Negative   469       168      637 \n",
       "Postive    83        710      793 \n",
       "All        552       878      1430"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model.predict(test_X_category_B)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target_category_B, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target_category_B, y_pred))\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target_category_B, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hyper Parameters Tuning of SVM model using Grid Search </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to tune the model using Grid Search. In SVM model, kernel, gammas and C value plays an important role.\n",
    "C controls the trade off between smooth decision boundary and classifying the training points correctly. Gamma is a parameter for non linear hyperplanes. Higher value of gamma tries to exactly fit the training data set. Kernel parameters is used to select the type of hyperplane which will be used to separate the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels = ['linear', 'rbf', 'poly']\n",
    "gammas = [0.1, 1, 10, 100]\n",
    "cs = [0.1, 1, 10, 100, 1000]\n",
    "param_grid = dict(kernel=kernels, C= cs, gamma=gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'kernel': ['linear', 'rbf', 'poly'], 'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(SVC(), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(train_X, train_target_category_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8609206660137121"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print details\n",
    "print(\"Best parameters set found on training set:\")\n",
    "display(grid.best_params_)\n",
    "display(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the best parameters to make predictions on the test datasets of same category and different category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_tuned = SVC(kernel='rbf',C=10,gamma= 1)\n",
    "svc_model_tuned.fit(train_X, train_target_category_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the same category test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.84      0.76      0.80       146\n",
      "     Postive       0.89      0.93      0.91       292\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       438\n",
      "   macro avg       0.86      0.84      0.85       438\n",
      "weighted avg       0.87      0.87      0.87       438\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>111</td>\n",
       "      <td>35</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>21</td>\n",
       "      <td>271</td>\n",
       "      <td>292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>132</td>\n",
       "      <td>306</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   111       35       146\n",
       "Postive    21        271      292\n",
       "All        132       306      438"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model_tuned.predict(test_X_category_A)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target_category_A, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target_category_A, y_pred))\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target_category_A, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the different category test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.87      0.72      0.79       637\n",
      "     Postive       0.80      0.91      0.85       793\n",
      "\n",
      "   micro avg       0.83      0.83      0.83      1430\n",
      "   macro avg       0.84      0.82      0.82      1430\n",
      "weighted avg       0.83      0.83      0.82      1430\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>456</td>\n",
       "      <td>181</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>68</td>\n",
       "      <td>725</td>\n",
       "      <td>793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>524</td>\n",
       "      <td>906</td>\n",
       "      <td>1430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive   All\n",
       "True                              \n",
       "Negative   456       181      637 \n",
       "Postive    68        725      793 \n",
       "All        524       906      1430"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model_tuned.predict(test_X_category_B)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target_category_B, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target_category_B, y_pred))\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target_category_B, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Evaluation \n",
    "<a id=\"task_3_1\"></a>\n",
    "\n",
    "1) In Part 1 of task 3 we have to train a classification model on the data from “Category A”, and evaluate its performance on the test data from \"Category A\" and “Category B”. In our case Category 1 is bars and Category 2 is Hotels and Travel <br/>\n",
    "\n",
    "2) In previous part, we saw that for Bars dataset, SVM was giving us best accuracy and F1 Score on the test dataset and also by evaluating it using cross-validation. So in this part, we have used SVM to train our model on bars training dataset and then we have predicted the value of test data of bars and also Hotels and Travel Dataset. <br/>\n",
    "\n",
    "3) <b>As a result we can see that a model trained on bar reviews has 86% accuracy when tested on Bar review and 82% accuracy when tested on hotels and travel review.</b>\n",
    " \n",
    "4) Also after fine tuning SVM model we were able to get 87% Accuracy on bar review test dataset and 83% accuracy on hotels and travel test dataset. Best parameters after fine tuning SVM were {'C': 1, 'gamma': 0.1, 'kernel': 'linear'}. </br>\n",
    "\n",
    "5) We can see that there is only slight(4%) difference in the accuracy when model was tested on same category test data and when tested on different category test data. This shows that document-term matrix which was created for bars dataset can be used to evaluate \"Hotels and Travel\" dataset very efficiently. The knowledge transfer from bar dataset to hotels and travel is very efficient. We can use the trained model to predict data from both the categories with good accuracy.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2\n",
    "\n",
    "Train a classification model on the data from “Category B”, and evaluate its performance on the data from “Category A” <br/>\n",
    "In our Case, Category A is now \"Hotels and Travel\" and Category B is \"Bar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category A\n",
    "train_documents=hotels_travel_dataset['Review Text']\n",
    "train_target=hotels_travel_dataset['class_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are splitting the data in training and testing. Testing data would be used to evalaute the model trained on same category. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents_category_A, test_documents_category_A, train_target_category_A, test_target_category_A \\\n",
    "= train_test_split(train_documents, train_target, random_state=0,train_size = 0.7,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would be using this data to evalaute the model trained on different category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Category B (Test Dataset)\n",
    "test_documents_category_B=bars_dataset['Review Text']\n",
    "test_target_category_B=bars_dataset['class_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are them transforming the list of Review text into a document-term matrix by applying some pre-processing steps. We have used the same approach that we have followed in above part. Using a custom lemma_tokenizer to perform tokenization. In that function we have handled stopwords and also performed the lemmatization of tokens. We have converted everything to lower case and discarded words which appear in less than 3 documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5100)\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = CountVectorizer(stop_words=\"english\",min_df = 3,tokenizer=lemma_tokenizer)\n",
    "vectorizer = TfidfVectorizer(min_df = 3,tokenizer=lemma_tokenizer,ngram_range=(1, 2))\n",
    "train_X = vectorizer.fit_transform(train_documents_category_A)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating document-term matrix from test documents by calling transform() method to use the same vocabulary as the of training dataset. We will use text_X in the below model for testing purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector for test documents of same category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(429, 5100)\n"
     ]
    }
   ],
   "source": [
    "test_X_category_A = vectorizer.transform(test_documents_category_A)\n",
    "print(test_X_category_A.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector for test documents from different category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 5100)\n"
     ]
    }
   ],
   "source": [
    "test_X_category_B = vectorizer.transform(test_documents_category_B)\n",
    "print(test_X_category_B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous part, we saw that <b>SVM model</b> was giving us the best accuracy. So we will use that model to evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = SVC(kernel='linear')\n",
    "svc_model.fit(train_X, train_target_category_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the same category test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.85      0.88       194\n",
      "     Postive       0.88      0.93      0.91       235\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       429\n",
      "   macro avg       0.90      0.89      0.89       429\n",
      "weighted avg       0.90      0.90      0.89       429\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>165</td>\n",
       "      <td>29</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>16</td>\n",
       "      <td>219</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>181</td>\n",
       "      <td>248</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   165       29       194\n",
       "Postive    16        219      235\n",
       "All        181       248      429"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model.predict(test_X_category_A)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target_category_A, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target_category_A, y_pred))\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target_category_A, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the different category test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.70      0.78       565\n",
      "     Postive       0.83      0.94      0.88       895\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1460\n",
      "   macro avg       0.85      0.82      0.83      1460\n",
      "weighted avg       0.85      0.85      0.84      1460\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>394</td>\n",
       "      <td>171</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>55</td>\n",
       "      <td>840</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>449</td>\n",
       "      <td>1011</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive   All\n",
       "True                              \n",
       "Negative   394       171      565 \n",
       "Postive    55        840      895 \n",
       "All        449       1011     1460"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model.predict(test_X_category_B)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target_category_B, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target_category_B, y_pred))\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target_category_B, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Hyper Parameters Tuning of SVM model using Grid Search </b><br/>\n",
    "We can try to tune the model using Grid Search. In SVM model, kernel, gammas and C value plays an important role. C controls the trade off between smooth decision boundary and classifying the training points correctly. Gamma is a parameter for non linear hyperplanes. Higher value of gamma tries to exactly fit the training data set. Kernel parameters is used to select the type of hyperplane which will be used to separate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = [0.1, 1, 10, 100]\n",
    "cs = [0.1, 1, 10, 100, 1000]\n",
    "param_grid = dict( C= cs, gamma=gammas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.1, 1, 10, 100]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the grid\n",
    "grid = GridSearchCV(SVC(kernel='linear'), param_grid, cv=5, scoring='accuracy')\n",
    "grid.fit(train_X, train_target_category_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set found on training set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'gamma': 0.1}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.88"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print details\n",
    "print(\"Best parameters set found on training set:\")\n",
    "display(grid.best_params_)\n",
    "display(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the best parameters to make predictions on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model_tuned = SVC(kernel='linear',C=1,gamma= 1)\n",
    "svc_model_tuned.fit(train_X, train_target_category_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the same category test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.91      0.85      0.88       194\n",
      "     Postive       0.88      0.93      0.91       235\n",
      "\n",
      "   micro avg       0.90      0.90      0.90       429\n",
      "   macro avg       0.90      0.89      0.89       429\n",
      "weighted avg       0.90      0.90      0.89       429\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>165</td>\n",
       "      <td>29</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>16</td>\n",
       "      <td>219</td>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>181</td>\n",
       "      <td>248</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive  All\n",
       "True                             \n",
       "Negative   165       29       194\n",
       "Postive    16        219      235\n",
       "All        181       248      429"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model_tuned.predict(test_X_category_A)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target_category_A, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target_category_A, y_pred))\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target_category_A, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are making predictions on the different category test dataset and comparing it's value with the actual result to find the accuracy score. We are also creating a confusion matrix, which summarises different aspects of classifier performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy = 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.88      0.70      0.78       565\n",
      "     Postive       0.83      0.94      0.88       895\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      1460\n",
      "   macro avg       0.85      0.82      0.83      1460\n",
      "weighted avg       0.85      0.85      0.84      1460\n",
      "\n",
      "Confusion Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Postive</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>394</td>\n",
       "      <td>171</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Postive</th>\n",
       "      <td>55</td>\n",
       "      <td>840</td>\n",
       "      <td>895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>449</td>\n",
       "      <td>1011</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  Negative  Postive   All\n",
       "True                              \n",
       "Negative   394       171      565 \n",
       "Postive    55        840      895 \n",
       "All        449       1011     1460"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_model_tuned.predict(test_X_category_B)\n",
    "# Print performance details\n",
    "accuracy = metrics.accuracy_score(test_target_category_B, y_pred) # , normalize=True, sample_weight=None\n",
    "print(\"Classification accuracy = %.2f\" % accuracy)\n",
    "print(metrics.classification_report(test_target_category_B, y_pred))\n",
    "# Print confusion matrix\n",
    "print(\"Confusion Matrix\")\n",
    "pd.crosstab(test_target_category_B, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Evaluation \n",
    "<a id=\"task_3_2\"></a>\n",
    "\n",
    "1) In Part 2 of task 3 we have to train a classification model on the data from “Category A”, and evaluate its performance on the test data from \"Category A\" and “Category B”. In our case Category 1 is Hotels and Travel and Category 2 is bars <br/>\n",
    "\n",
    "2) In previous part, we saw that for Hotels and Travel dataset, SVM was giving us best accuracy and F1 Score on the test dataset and also by evaluating it using cross-validation. So in this part, we have used SVM to train our model on Hotels and Travel training dataset and then we have predicted the value of test data of Hotels and Travel and also Bars Dataset. <br/>\n",
    "\n",
    "3) <b>As a result we can see that a model trained on Hotels and Travel reviews has 90% accuracy when tested on Hotels and Travel review and 85% accuracy when tested on bars review.</b>\n",
    " \n",
    "4) Also after fine tuning SVM model we were able to get same accuracy. </br>\n",
    "\n",
    "5) We can see that there is only slight(5%) difference in the accuracy when model was tested on same category test data and when tested on different category test data. This shows that document-term matrix which was created for Hotels and Travel dataset can be used to evaluate \"Bars\" dataset very efficiently. The knowledge transfer from Hotels and Travel dataset to bars is very efficient. We can use the trained model to predict data from both the categories with good accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, we have divided Task 2 in two parts. First part involves training and testing Category 1 data that is Hotels and Travel and in second part, we are training and testing Category 2 data that is Bars. I have included the result and analysis, after executing each part. <br/>\n",
    "You can check the Analysis of Task 2 from below cells- <br/>\n",
    "[Result of Hotels and Travel Dataset](#task_2_1)<br/>\n",
    "[Result of Bars Dataset](#task_2_2)<br/>\n",
    "You can check the Analysis of Task 3 from below cells- <br/>\n",
    "[Part 1- Category 1 as training data and Category 2 as test data](#task_3_1)<br/>\n",
    "[Part 2- Category 2 as training data and Category 1 as test data](#task_3_2)<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. From the results, we can see that SVM has given us the best accuracy and F1-Score as compared to Naive Bayes and K-nearest neighbors algorithm.<br/>\n",
    "2. One of the reason can be that SVM works well with <b>high dimensional data</b> like we have in our text analysis case. Also the risk of <b>over-fitting is less</b> in SVM models, making it more robust. <br/>\n",
    "3. One of the disadvantage is that training and fine tuning a SVM model takes more time as compared to other two models. <br/>\n",
    "4. On the other hand we can see that Naive Bayes is also giving us good result despite the fact that it treats each feature independently. It is easy to train and implement a naive bayes model. And also fine tuning is much easier and less computationally expensive than SVM model.<br/>\n",
    "5. If we look at the result of task 3, we can see that a model trained on Hotels and travel dataset, can predict the value of bars dataset with high accuracy. And similar is the result in other case, when we trained our model on Bars dataset and used hotels and travel dataset for evaluation. <br/>\n",
    "6. A model trained on bar reviews has 86% accuracy when tested on Bar review and 82% accuracy when tested on hotels and travel review.<br/>\n",
    "7. A model trained on Hotels and Travel reviews has 90% accuracy when tested on Hotels and Travel review and 85% accuracy when tested on bars review<br/>\n",
    "8. This shows that both dataset have similar kind of words which makes a review positive or negative. Since hotels and travel category and bars category comes under same domain, there is high probability of similar kind of reviews. That's why we are getting high accuracy in both the cases.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
